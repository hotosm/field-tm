# Copyright (c) Humanitarian OpenStreetMap Team
#
# This file is part of Field-TM.
#
#     Field-TM is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     Field-TM is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with Field-TM.  If not, see <https:#www.gnu.org/licenses/>.
#

# List available commands
[private]
default:
  just --justfile {{justfile()}} --list test

# Test backend & frontend
[no-cd]
all: backend frontend

# Test all backend code (including packages)
[no-cd]
backend:
  just build backend
  # Start all service and ensure API has finish init process
  docker compose -f compose.test.yaml up --detach
  docker compose -f compose.test.yaml run --rm api pytest

# Test backend API only
[no-cd]
api:
  # Start all service and ensure API has finish init process
  docker compose -f compose.test.yaml up --detach
  docker compose -f compose.test.yaml run --rm api pytest tests

# Test osm-fieldwork package only
[no-cd]
osm-fieldwork:
  # Start all service and ensure API has finish init process
  docker compose -f compose.test.yaml up --detach
  docker compose -f compose.test.yaml run --rm api pytest package_tests/test_osm_fieldwork

# Test area-splitter package only
[no-cd]
splitter:
  # Start all service and ensure API has finish init process
  docker compose -f compose.test.yaml up --detach
  docker compose -f compose.test.yaml run --rm api pytest package_tests/test_area_splitter

# Run all frontend tests
[no-cd]
frontend:
  just test frontend-unit
  just test frontend-e2e

# Test frontend with vitest
[no-cd]
frontend-unit:
  docker compose \
    run --rm --entrypoint='sh -c' \
    ui-mapper 'npm run test:unit'

# Test frontend with Playwright
[no-cd]
frontend-e2e:
  docker compose \
    -f compose.yaml \
    -f contrib/playwright/compose.yaml \
  run --rm --service-ports ui-test 'npm run test:e2e-report'

# View Playwright tests as they happen in browser
[no-cd]
frontend-e2e-debug:
  docker compose \
    -f compose.yaml \
    -f contrib/playwright/compose.yaml \
  run --rm ui-test 'npm run test:e2e-debug'

# Create Playwright tests interactively
[no-cd]
frontend-e2e-interactive:
  docker compose \
    -f compose.yaml \
    -f contrib/playwright/compose.yaml \
  run --rm ui-test 'npm run test:e2e-interactive'

# Test mapper frontend build for offline testing
[no-cd]
mapper-preview:
  #!/usr/bin/env sh
  cd {{justfile_directory()}}/src/mapper
  pnpm install
  VITE_API_URL=http://api.fmtm.localhost:7050 \
    VITE_SYNC_URL=http://sync.fmtm.localhost:7050 \
    VITE_S3_URL=http://s3.fmtm.localhost:7050 \
    pnpm run build
  pnpm run preview

# Copy prod data into current database (WARNING: deletes local db data)
[no-cd]
init-prod-data:
  #!/usr/bin/env sh
  # cd {{justfile_directory()}}

  # If ODK S3 vars not present, skip
  just test _check-odk-s3-env-vars || exit 1

  echo "Deleting local db data"
  docker compose down -v
  echo "Starting S3 and local databases only"
  # Note cannot start electric as the logical replication slot cannot be used
  docker compose up -d s3 fmtm-db central-db

  # Set Minio aliases for connection (no creds needed for prod backup download currently)
  docker compose exec --no-TTY s3 mc alias set fmtm-prod https://s3.fmtm.hotosm.org "" ""
  docker compose exec --no-TTY s3 mc alias set local "$S3_ENDPOINT" "$S3_ACCESS_KEY" "$S3_SECRET_KEY"
  docker compose exec --no-TTY s3 mc alias set odk-prod \
    "$CENTRAL_BACKUP_S3_ENDPOINT" "$CENTRAL_BACKUP_S3_ACCESS_KEY" "$CENTRAL_BACKUP_S3_SECRET_KEY"
  # We also need to create the fmtm-data bucket, as the migration service has not ran
  docker compose exec --no-TTY s3 mc mb "local/${S3_BUCKET_NAME}" --ignore-existing
  docker compose exec --no-TTY s3 mc anonymous set download "local/${S3_BUCKET_NAME}"

  # Load database data
  just test _load-prod-db-data fmtm-prod/fmtm-db-backups/fmtm fmtm-db ${FMTM_DB_NAME} ${FMTM_DB_USER} ${FMTM_DB_PASSWORD}
  just test _load-prod-db-data odk-prod/odkbackup central-db ${CENTRAL_DB_NAME} ${CENTRAL_DB_USER} ${CENTRAL_DB_PASSWORD}

  # Copy S3 data to local
  just test _mirror-s3-bucket fmtm-prod/fmtm-data local/fmtm-data
  # We skip the hotosm-odk-uploads as it could be large >10GB in prod
  # just test _mirror-s3-bucket odk-prod/hotosm-odk-uploads local/fmtm-odk-media

  just test _print-post-data-load-instructions

[no-cd]
[no-exit-message]
_check-odk-s3-env-vars:
  #!/usr/bin/env sh
  just config _dotenv-check CENTRAL_BACKUP_S3_ENDPOINT || exit 1
  just config _dotenv-check CENTRAL_BACKUP_S3_DB_BUCKET_NAME || exit 1
  just config _dotenv-check CENTRAL_BACKUP_S3_BLOB_BUCKET_NAME || exit 1
  just config _dotenv-check CENTRAL_BACKUP_S3_ACCESS_KEY || exit 1
  just config _dotenv-check CENTRAL_BACKUP_S3_SECRET_KEY || exit 1

[no-cd]
_mirror-s3-bucket source target:
  #!/usr/bin/env sh
  docker compose exec --no-TTY s3 \
    mc mirror --overwrite --summary {{ source }} {{ target }}

  just _echo-blue "S3 mirroring from {{ source }} to {{ target }} done."

[no-cd]
_load-prod-db-data s3_root db_host db_name db_user db_pass:
  #!/usr/bin/env sh
  # Get latest db dump filename
  latest_file=$(docker compose exec --no-TTY s3 mc ls {{ s3_root }} \
    | awk '{print $NF}' | sort | tail -n 1)
  echo "Latest backup file: $latest_file"

  # Copy file to current machine
  docker compose exec --no-TTY s3 \
    mc cp {{ s3_root }}/"$latest_file" /tmp/"$latest_file"
  docker compose cp s3:/tmp/"$latest_file" /tmp/"$latest_file"

  echo "Dropping existing database {{ db_name }} as user {{ db_user }}"
  docker compose exec --no-TTY -e PGPASSWORD={{ db_pass }} {{ db_host }} \
    dropdb --echo --if-exists --force -U {{ db_user }} {{ db_name }}

  echo "Creating new database {{ db_name }} as user {{ db_user }}"
  docker compose exec --no-TTY -e PGPASSWORD={{ db_pass }} {{ db_host }} \
    createdb --echo -U {{ db_user }} -O {{ db_user }} {{ db_name }}

  echo "Loading data into database {{ db_name }} as user {{ db_user }}"
  gunzip -c /tmp/"$latest_file" | \
  docker compose exec --no-TTY -e PGPASSWORD={{ db_pass }} {{ db_host }} \
    pg_restore --verbose -U {{ db_user }} -d {{ db_name }}

  just _echo-blue "Data load for {{ db_host }} done."

[no-cd]
_print-post-data-load-instructions:
  #!/usr/bin/env sh
  echo
  just _echo-yellow " ############################################################################"
  echo
  echo " Data loading done!"
  echo
  just _echo-blue " Please update the 'ENCRYPTION_KEY' in '.env' to match production"
  echo
  echo " Then restart all services using:"
  echo
  just _echo-blue "     docker compose down"
  just _echo-blue "     docker compose up -d"
  echo
  just _echo-yellow " **WARNING**: this will use production ODK!"
  just _echo-yellow " If creating a new project, be sure to update the HOTOSM organisation"
  just _echo-yellow " in the database to use the local ODK!"
  echo
  just _echo-yellow " ############################################################################"
  echo

# Run load test on backend API (e.g. just test load projects/62/minimal)
[no-cd]
load url_path:
  docker compose \
    -f contrib/load_testing/compose.yaml \
    run --rm k6 run /load-test.js -e url_path={{ url_path }}

# Check coverage for backend tests
[no-cd]
backend-coverage:
  #!/usr/bin/env sh
  set -eux

  export TAG_OVERRIDE=ci-dev
  just build backend

  # Cleanup any missed previous container
  docker rm --force backend-coverage-run

  # Start all service and ensure API has finish init process
  # Note that compose returns exit code 0 for ui builds, but that's ok
  docker compose -f compose.test.yaml up --detach
  docker compose -f compose.test.yaml run \
    --name backend-coverage-run \
    --entrypoint="sh -c" \
    api \
    "coverage run -m pytest \
      && coverage report && coverage html \
      && coverage-badge -o coverage.svg"

  # Copy generated coverage files out
  mkdir -p coverage
  docker cp backend-coverage-run:/opt/htmlcov/index.html coverage/coverage.html
  docker cp backend-coverage-run:/opt/coverage.svg coverage/coverage.svg
  docker rm backend-coverage-run

# Upload coverage report to gh-pages
[no-cd]
upload-coverage:
  #!/usr/bin/env sh
  set -eux

  : "${GITHUB_TOKEN:?GITHUB_TOKEN  environment variable must be set}"

  rm -rf tmp_pages
  mkdir tmp_pages
  cd tmp_pages

  git init --initial-branch=gh-pages
  git config user.name "svchot"
  git config user.email "sysadmin@hotosm.org"
  git pull "https://x-access-token:${GITHUB_TOKEN}@github.com/hotosm/field-tm.git" gh-pages || echo "No remote branch yet"

  # Copy coverage.svg and coverage.html from main repo
  cp ../coverage/* .

  git add .
  git commit -m "docs: update coverage summary and badge" || echo "Nothing to commit"
  git push --set-upstream "https://x-access-token:${GITHUB_TOKEN}@github.com/hotosm/field-tm.git" HEAD:gh-pages

# Upload coverage report to gh-pages
[no-cd]
backend-with-coverage-upload:
  just test backend-coverage
  just test upload-coverage
